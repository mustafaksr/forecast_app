Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to 'autogluon-m4-hourly'
=================== System Info ===================
AutoGluon Version:  1.1.1
Python Version:     3.10.14
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #38-Ubuntu SMP PREEMPT_DYNAMIC Fri Jun  7 15:25:01 UTC 2024
CPU Count:          4
GPU Count:          0
Memory Avail:       4.78 GB / 9.64 GB (49.7%)
Disk Space Avail:   402.90 GB / 931.51 GB (43.3%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 48,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'item_id',
 'time_limit': 10,
 'verbosity': 2}

Warning: path already exists! This predictor may overwrite an existing predictor! path="autogluon-m4-hourly"
Beginning AutoGluon training... Time limit = 10s
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to 'autogluon-m4-hourly'
AutoGluon will save models to 'autogluon-m4-hourly'
=================== System Info ===================
AutoGluon Version:  1.1.1
Python Version:     3.10.14
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #38-Ubuntu SMP PREEMPT_DYNAMIC Fri Jun  7 15:25:01 UTC 2024
CPU Count:          4
GPU Count:          0
Memory Avail:       4.64 GB / 9.64 GB (48.1%)
Disk Space Avail:   402.90 GB / 931.51 GB (43.3%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.1.1
Python Version:     3.10.14
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #38-Ubuntu SMP PREEMPT_DYNAMIC Fri Jun  7 15:25:01 UTC 2024
CPU Count:          4
GPU Count:          0
Memory Avail:       4.64 GB / 9.64 GB (48.1%)
Disk Space Avail:   402.90 GB / 931.51 GB (43.3%)
===================================================
Setting presets to: medium_quality
Setting presets to: medium_quality

Fitting with arguments:

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 48,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 48,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'h'
Inferred time series frequency: 'h'
Provided train_data has 148060 rows, 200 time series. Median time series length is 700 (min=700, max=960). 
Provided train_data has 148060 rows, 200 time series. Median time series length is 700 (min=700, max=960). 

Provided data contains following columns:

Provided data contains following columns:
	target: 'target'
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================
===================================================

Starting training. Start time is 2024-07-19 11:48:43

Starting training. Start time is 2024-07-19 11:48:43
Models that will be trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'TemporalFusionTransformer']
Models that will be trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'TemporalFusionTransformer']
Training timeseries model Naive. Training for up to 1.2s of the 9.8s of remaining time.
Training timeseries model Naive. Training for up to 1.2s of the 9.8s of remaining time.
	Time limit exceeded... Skipping Naive.
	Time limit exceeded... Skipping Naive.
Training timeseries model SeasonalNaive. Training for up to 1.2s of the 8.4s of remaining time.
Training timeseries model SeasonalNaive. Training for up to 1.2s of the 8.4s of remaining time.
	Time limit exceeded... Skipping SeasonalNaive.
	Time limit exceeded... Skipping SeasonalNaive.
Training timeseries model RecursiveTabular. Training for up to 1.2s of the 7.0s of remaining time.
Training timeseries model RecursiveTabular. Training for up to 1.2s of the 7.0s of remaining time.
	Warning: Exception caused RecursiveTabular to fail during training... Skipping this model.
	Warning: Exception caused RecursiveTabular to fail during training... Skipping this model.
	Not enough time left to train models. Consider specifying a larger time_limit. Time remaining: -1.21s
	Not enough time left to train models. Consider specifying a larger time_limit. Time remaining: -1.21s
Training timeseries model DirectTabular. Training for up to 0.9s of the 4.6s of remaining time.
Training timeseries model DirectTabular. Training for up to 0.9s of the 4.6s of remaining time.
	Warning: Exception caused DirectTabular to fail during training... Skipping this model.
	Warning: Exception caused DirectTabular to fail during training... Skipping this model.
	Not enough time left to train models. Consider specifying a larger time_limit. Time remaining: -0.51s
	Not enough time left to train models. Consider specifying a larger time_limit. Time remaining: -0.51s
Training timeseries model ETS. Training for up to 0.8s of the 3.2s of remaining time.
Training timeseries model ETS. Training for up to 0.8s of the 3.2s of remaining time.
	Time limit exceeded... Skipping ETS.
	Time limit exceeded... Skipping ETS.
Training timeseries model Theta. Training for up to 1.1s of the 3.2s of remaining time.
Training timeseries model Theta. Training for up to 1.1s of the 3.2s of remaining time.
	Time limit exceeded... Skipping Theta.
	Time limit exceeded... Skipping Theta.
Training timeseries model TemporalFusionTransformer. Training for up to 1.6s of the 3.1s of remaining time.
Training timeseries model TemporalFusionTransformer. Training for up to 1.6s of the 3.1s of remaining time.
	-6.2337       = Validation score (-MASE)
	-6.2337       = Validation score (-MASE)
	4.61    s     = Training runtime
	4.61    s     = Training runtime
	0.43    s     = Validation (prediction) runtime
	0.43    s     = Validation (prediction) runtime
Not fitting ensemble due to lack of time remaining. Time left: -1.9 seconds
Not fitting ensemble due to lack of time remaining. Time left: -1.9 seconds
Training complete. Models trained: ['TemporalFusionTransformer']
Training complete. Models trained: ['TemporalFusionTransformer']
Total runtime: 11.84 s
Total runtime: 11.84 s
Best model: TemporalFusionTransformer
Best model: TemporalFusionTransformer
Best model score: -6.2337
Best model score: -6.2337
Model not specified in predict, will default to the model with the best validation score: TemporalFusionTransformer
Model not specified in predict, will default to the model with the best validation score: TemporalFusionTransformer
Additional data provided, testing on additional data. Resulting leaderboard will be sorted according to test score (`score_test`).
Additional data provided, testing on additional data. Resulting leaderboard will be sorted according to test score (`score_test`).
Beginning AutoGluon training... Time limit = 10s
Beginning AutoGluon training... Time limit = 10s
Beginning AutoGluon training... Time limit = 10s
AutoGluon will save models to 'autogluon-m4-hourly'
AutoGluon will save models to 'autogluon-m4-hourly'
AutoGluon will save models to 'autogluon-m4-hourly'
=================== System Info ===================
AutoGluon Version:  1.1.1
Python Version:     3.10.14
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #38-Ubuntu SMP PREEMPT_DYNAMIC Fri Jun  7 15:25:01 UTC 2024
CPU Count:          4
GPU Count:          0
Memory Avail:       4.18 GB / 9.64 GB (43.4%)
Disk Space Avail:   402.89 GB / 931.51 GB (43.3%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.1.1
Python Version:     3.10.14
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #38-Ubuntu SMP PREEMPT_DYNAMIC Fri Jun  7 15:25:01 UTC 2024
CPU Count:          4
GPU Count:          0
Memory Avail:       4.18 GB / 9.64 GB (43.4%)
Disk Space Avail:   402.89 GB / 931.51 GB (43.3%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.1.1
Python Version:     3.10.14
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #38-Ubuntu SMP PREEMPT_DYNAMIC Fri Jun  7 15:25:01 UTC 2024
CPU Count:          4
GPU Count:          0
Memory Avail:       4.18 GB / 9.64 GB (43.4%)
Disk Space Avail:   402.89 GB / 931.51 GB (43.3%)
===================================================
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 48,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 48,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 48,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 10,
 'verbosity': 2}

Inferred time series frequency: 'h'
Inferred time series frequency: 'h'
Inferred time series frequency: 'h'
Provided train_data has 148060 rows, 200 time series. Median time series length is 700 (min=700, max=960). 
Provided train_data has 148060 rows, 200 time series. Median time series length is 700 (min=700, max=960). 
Provided train_data has 148060 rows, 200 time series. Median time series length is 700 (min=700, max=960). 

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:
	target: 'target'
	target: 'target'
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================
===================================================
===================================================

Starting training. Start time is 2024-07-19 11:49:02

Starting training. Start time is 2024-07-19 11:49:02

Starting training. Start time is 2024-07-19 11:49:02
Models that will be trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'TemporalFusionTransformer']
Models that will be trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'TemporalFusionTransformer']
Models that will be trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'TemporalFusionTransformer']
Training timeseries model Naive. Training for up to 1.2s of the 9.9s of remaining time.
Training timeseries model Naive. Training for up to 1.2s of the 9.9s of remaining time.
Training timeseries model Naive. Training for up to 1.2s of the 9.9s of remaining time.
	Time limit exceeded... Skipping Naive.
	Time limit exceeded... Skipping Naive.
	Time limit exceeded... Skipping Naive.
Training timeseries model SeasonalNaive. Training for up to 1.2s of the 8.5s of remaining time.
Training timeseries model SeasonalNaive. Training for up to 1.2s of the 8.5s of remaining time.
Training timeseries model SeasonalNaive. Training for up to 1.2s of the 8.5s of remaining time.
	Time limit exceeded... Skipping SeasonalNaive.
	Time limit exceeded... Skipping SeasonalNaive.
	Time limit exceeded... Skipping SeasonalNaive.
Training timeseries model RecursiveTabular. Training for up to 1.2s of the 7.1s of remaining time.
Training timeseries model RecursiveTabular. Training for up to 1.2s of the 7.1s of remaining time.
Training timeseries model RecursiveTabular. Training for up to 1.2s of the 7.1s of remaining time.
	-1.1427       = Validation score (-MASE)
	-1.1427       = Validation score (-MASE)
	-1.1427       = Validation score (-MASE)
	1.96    s     = Training runtime
	1.96    s     = Training runtime
	1.96    s     = Training runtime
	1.57    s     = Validation (prediction) runtime
	1.57    s     = Validation (prediction) runtime
	1.57    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 0.7s of the 3.5s of remaining time.
Training timeseries model DirectTabular. Training for up to 0.7s of the 3.5s of remaining time.
Training timeseries model DirectTabular. Training for up to 0.7s of the 3.5s of remaining time.
	Warning: Exception caused DirectTabular to fail during training... Skipping this model.
	Warning: Exception caused DirectTabular to fail during training... Skipping this model.
	Warning: Exception caused DirectTabular to fail during training... Skipping this model.
	Not enough time left to train models. Consider specifying a larger time_limit. Time remaining: -0.08s
	Not enough time left to train models. Consider specifying a larger time_limit. Time remaining: -0.08s
	Not enough time left to train models. Consider specifying a larger time_limit. Time remaining: -0.08s
Training timeseries model ETS. Training for up to 0.7s of the 2.8s of remaining time.
Training timeseries model ETS. Training for up to 0.7s of the 2.8s of remaining time.
Training timeseries model ETS. Training for up to 0.7s of the 2.8s of remaining time.
	Time limit exceeded... Skipping ETS.
	Time limit exceeded... Skipping ETS.
	Time limit exceeded... Skipping ETS.
Training timeseries model Theta. Training for up to 0.9s of the 2.8s of remaining time.
Training timeseries model Theta. Training for up to 0.9s of the 2.8s of remaining time.
Training timeseries model Theta. Training for up to 0.9s of the 2.8s of remaining time.
	Time limit exceeded... Skipping Theta.
	Time limit exceeded... Skipping Theta.
	Time limit exceeded... Skipping Theta.
Training timeseries model TemporalFusionTransformer. Training for up to 1.4s of the 2.7s of remaining time.
Training timeseries model TemporalFusionTransformer. Training for up to 1.4s of the 2.7s of remaining time.
Training timeseries model TemporalFusionTransformer. Training for up to 1.4s of the 2.7s of remaining time.
Beginning AutoGluon training... Time limit = 120s
Beginning AutoGluon training... Time limit = 120s
Beginning AutoGluon training... Time limit = 120s
Beginning AutoGluon training... Time limit = 120s
AutoGluon will save models to 'autogluon-m4-hourly'
AutoGluon will save models to 'autogluon-m4-hourly'
AutoGluon will save models to 'autogluon-m4-hourly'
AutoGluon will save models to 'autogluon-m4-hourly'
=================== System Info ===================
AutoGluon Version:  1.1.1
Python Version:     3.10.14
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #38-Ubuntu SMP PREEMPT_DYNAMIC Fri Jun  7 15:25:01 UTC 2024
CPU Count:          4
GPU Count:          0
Memory Avail:       3.85 GB / 9.64 GB (40.0%)
Disk Space Avail:   402.84 GB / 931.51 GB (43.2%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.1.1
Python Version:     3.10.14
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #38-Ubuntu SMP PREEMPT_DYNAMIC Fri Jun  7 15:25:01 UTC 2024
CPU Count:          4
GPU Count:          0
Memory Avail:       3.85 GB / 9.64 GB (40.0%)
Disk Space Avail:   402.84 GB / 931.51 GB (43.2%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.1.1
Python Version:     3.10.14
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #38-Ubuntu SMP PREEMPT_DYNAMIC Fri Jun  7 15:25:01 UTC 2024
CPU Count:          4
GPU Count:          0
Memory Avail:       3.85 GB / 9.64 GB (40.0%)
Disk Space Avail:   402.84 GB / 931.51 GB (43.2%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.1.1
Python Version:     3.10.14
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #38-Ubuntu SMP PREEMPT_DYNAMIC Fri Jun  7 15:25:01 UTC 2024
CPU Count:          4
GPU Count:          0
Memory Avail:       3.85 GB / 9.64 GB (40.0%)
Disk Space Avail:   402.84 GB / 931.51 GB (43.2%)
===================================================
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality
Setting presets to: medium_quality

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 48,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 120,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 48,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 120,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 48,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 120,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': MASE,
 'hyperparameters': 'light',
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 48,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 120,
 'verbosity': 2}

Inferred time series frequency: 'h'
Inferred time series frequency: 'h'
Inferred time series frequency: 'h'
Inferred time series frequency: 'h'
Provided train_data has 148060 rows, 200 time series. Median time series length is 700 (min=700, max=960). 
Provided train_data has 148060 rows, 200 time series. Median time series length is 700 (min=700, max=960). 
Provided train_data has 148060 rows, 200 time series. Median time series length is 700 (min=700, max=960). 
Provided train_data has 148060 rows, 200 time series. Median time series length is 700 (min=700, max=960). 

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:

Provided data contains following columns:
	target: 'target'
	target: 'target'
	target: 'target'
	target: 'target'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'

AutoGluon will gauge predictive performance using evaluation metric: 'MASE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================
===================================================
===================================================
===================================================

Starting training. Start time is 2024-07-19 11:49:12

Starting training. Start time is 2024-07-19 11:49:12

Starting training. Start time is 2024-07-19 11:49:12

Starting training. Start time is 2024-07-19 11:49:12
Models that will be trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'TemporalFusionTransformer']
Models that will be trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'TemporalFusionTransformer']
Models that will be trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'TemporalFusionTransformer']
Models that will be trained: ['Naive', 'SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'ETS', 'Theta', 'TemporalFusionTransformer']
Training timeseries model Naive. Training for up to 15.0s of the 119.9s of remaining time.
Training timeseries model Naive. Training for up to 15.0s of the 119.9s of remaining time.
Training timeseries model Naive. Training for up to 15.0s of the 119.9s of remaining time.
Training timeseries model Naive. Training for up to 15.0s of the 119.9s of remaining time.
	-6.3525       = Validation score (-MASE)
	-6.3525       = Validation score (-MASE)
	-6.3525       = Validation score (-MASE)
	-6.3525       = Validation score (-MASE)
	2.35    s     = Training runtime
	2.35    s     = Training runtime
	2.35    s     = Training runtime
	2.35    s     = Training runtime
	1.23    s     = Validation (prediction) runtime
	1.23    s     = Validation (prediction) runtime
	1.23    s     = Validation (prediction) runtime
	1.23    s     = Validation (prediction) runtime
Not fitting ensemble due to lack of time remaining. Time left: -0.9 seconds
Not fitting ensemble due to lack of time remaining. Time left: -0.9 seconds
Not fitting ensemble due to lack of time remaining. Time left: -0.9 seconds
Not fitting ensemble due to lack of time remaining. Time left: -0.9 seconds
Training complete. Models trained: ['RecursiveTabular', 'TemporalFusionTransformer']
Training complete. Models trained: ['RecursiveTabular', 'TemporalFusionTransformer']
Training complete. Models trained: ['RecursiveTabular', 'TemporalFusionTransformer']
Training complete. Models trained: ['RecursiveTabular', 'TemporalFusionTransformer']
Total runtime: 10.76 s
Total runtime: 10.76 s
Total runtime: 10.76 s
Total runtime: 10.76 s
Best model: RecursiveTabular
Best model: RecursiveTabular
Best model: RecursiveTabular
Best model: RecursiveTabular
Best model score: -1.1427
Best model score: -1.1427
Best model score: -1.1427
Best model score: -1.1427
	-6.6629       = Validation score (-MASE)
	-6.6629       = Validation score (-MASE)
	-6.6629       = Validation score (-MASE)
	-6.6629       = Validation score (-MASE)
	0.14    s     = Training runtime
	0.14    s     = Training runtime
	0.14    s     = Training runtime
	0.14    s     = Training runtime
	1.90    s     = Validation (prediction) runtime
	1.90    s     = Validation (prediction) runtime
	1.90    s     = Validation (prediction) runtime
	1.90    s     = Validation (prediction) runtime
Training timeseries model SeasonalNaive. Training for up to 16.8s of the 117.8s of remaining time.
Training timeseries model SeasonalNaive. Training for up to 16.8s of the 117.8s of remaining time.
Training timeseries model SeasonalNaive. Training for up to 16.8s of the 117.8s of remaining time.
Training timeseries model SeasonalNaive. Training for up to 16.8s of the 117.8s of remaining time.
	-1.2169       = Validation score (-MASE)
	-1.2169       = Validation score (-MASE)
	-1.2169       = Validation score (-MASE)
	-1.2169       = Validation score (-MASE)
	0.12    s     = Training runtime
	0.12    s     = Training runtime
	0.12    s     = Training runtime
	0.12    s     = Training runtime
	0.30    s     = Validation (prediction) runtime
	0.30    s     = Validation (prediction) runtime
	0.30    s     = Validation (prediction) runtime
	0.30    s     = Validation (prediction) runtime
Training timeseries model RecursiveTabular. Training for up to 19.6s of the 117.4s of remaining time.
Training timeseries model RecursiveTabular. Training for up to 19.6s of the 117.4s of remaining time.
Training timeseries model RecursiveTabular. Training for up to 19.6s of the 117.4s of remaining time.
Training timeseries model RecursiveTabular. Training for up to 19.6s of the 117.4s of remaining time.
	-0.9339       = Validation score (-MASE)
	-0.9339       = Validation score (-MASE)
	-0.9339       = Validation score (-MASE)
	-0.9339       = Validation score (-MASE)
	17.00   s     = Training runtime
	17.00   s     = Training runtime
	17.00   s     = Training runtime
	17.00   s     = Training runtime
	1.75    s     = Validation (prediction) runtime
	1.75    s     = Validation (prediction) runtime
	1.75    s     = Validation (prediction) runtime
	1.75    s     = Validation (prediction) runtime
Training timeseries model DirectTabular. Training for up to 19.7s of the 98.6s of remaining time.
Training timeseries model DirectTabular. Training for up to 19.7s of the 98.6s of remaining time.
Training timeseries model DirectTabular. Training for up to 19.7s of the 98.6s of remaining time.
Training timeseries model DirectTabular. Training for up to 19.7s of the 98.6s of remaining time.
